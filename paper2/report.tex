\documentclass[sigconf]{acmart}


\input{format/i523}


\begin{document}
\title{Big Data Applications in Using Neural Networks for Medical Image Analysis}


\author{Tyler Peterson}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Indiana University - School of Informatics, Computing, and Engineering}
  \streetaddress{711 N. Park Avenue}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{typeter@iu.edu}


% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{G. v. Laszewski}


\begin{abstract}

 Medical image analysis is proving to be a promising domain for disruption by machine learning. The analysis of medical imagery has long been within the purview of radiologists, a specialization in medicine that reviews medical imaging to form diagnoses and advise on treatment options. Historically, radiologists have relied on their training, senses and years of experience to evaluate images for medical issues, such as the presence of tumors, lung nodules, and hip osteoarthritis. The presence of technology, generally referred to as computer-aided diagnosis (CAD) tools, has been growing over the last several decades, but modern computing power and sizable datasets have accelerated the effectiveness of these tools. Machine learning algorithms, especially artifical neural networks (ANN), are being leveraged to help identify abnormalities present in medical images at a high level of accuracy. Several research studies conclude that ANN techniques can match, and occassionally outperform, the abilities of radiologists. Big data and the application of advanced algorithms show promise for evolving our ability to successfully evaluate medical images and save lives in the process.      
  
\end{abstract}


\keywords{i523, hid331, Big Data, Medical Image Analysis, Artificial Neural Networks, Medicine}


\maketitle


\section{Introduction}

The analysis of medical imagery is primarily the responsibility of radiologists. These individuals are medical doctors who specialize in diagnosing diseases through review of images produced by various imaging modalities, such as x-ray, ultrasound, computerized tomography (CT), magnetic resonance imaging (MRI) and positron emission tomography (PET) \cite{cite00}. Radiologists serve as an expert to other physicians by analyzing the medical images of patients suspected of having certain medical issues, and by making recommendations on subsequent care based on the observations \cite{cite00}. The images reviewed by radiologists are generally stored digitially, and images are increasingly being stored in picture archiving and communications systems (PACS). These systems are required to keep up with the rapid accumulation of medical image data. Between 2005 and 2011, the medical image data in US hospitals increased from only 8,900 terabytes to 27,000 terabytes \cite{cite04}. That number is expected to grow by 20 percent every year due to increasing image size and resolution, the adoption of 3D imaging, and an aging population who will likely bring an increasing demand for medical imaging studies \cite{cite04}.

It is estimated that one billion medical images are created worldwide each year, and most of these are assessed by radiologists \cite{cite01}. Given that radiologists are human, their judgment is fallible. It is estimated that the lowest average error rate in analyzing medical imagery is 4 percent, which means collectively radiologists are estimated to make 40 million errors in judgement every year \cite{cite01}. A particularly striking example of fallibility comes from a study that analyzed the first and second interpretations of radiologists from Massachusetts General Hospital. They reviewed abdominal CTs and re-reviewed studies that had either been interpreted by themselves or a colleague. The study found that the radiologists disagreed with their peers 30 percent of the time and even disagreed with themselves 25 percent of the time \cite{cite01}.

There are two major types of radiologic analysis error: perceptual error and interpretive errors \cite{cite01}. Most errors, up to 80 percent, are perceptual errors, which occur when an abnormality is not perceived by the reviewer during the initial review, but is identified in a subsequent analysis \cite{cite01}. Interpretive errors occur when the radiologist successfully identifies the abnormality, but incorrectly diagnosis the problem, which may lead to a less appropriate course of careaction \cite{cite01}. There are several reasons why errors occur, including fatigue, excessive pace of analysis, distractions and insufficient knowledge of the practitioner. It is also asserted that the extreme complexity of a radiologist's job contributes to the errors. Errors occur in the practice of radiologists all across the world, at varying levels of training, in all imaging modalities and all clinical settings \cite{cite01}.

Over the last several decades, there has been an effort to develop computer-based tools to aid radiologists in the detection of abnormalities. Computer-aided diagnosis (CAD) tools are primarily intended to increase the rate at which problems are identified while also reducing the false negatives resulting from human error \cite{cite06} . These systems are intended to supplement, not replace, the radiologist by reporting a second opinion to be considered alongside the radiologist's assessment. The earliest initiatives to develop these tools occurred in the 1960s, and concerted efforts began in the 1980s \cite{cite02}. Despite the research being nearly 60 years old, widespread adoption is a relatively recent occurrence \cite{cite03}. Clinical studies reported early CAD implementations as being minimally effective. Specifically, CAD decisions included more false positives than human assessments, which created more work for radiologists and often led to additional, unnecessary medical tests and biopsies \cite{cite05}.

Several improvements in the field of computing have increased the accuracy of CAD tools and subsequently encouraged wider adoption of these tools into clinical workflows. The advancements includes increased access to digital imaging datasets, larger imaging data sets, increased used of imaging in healthcare and increased computing power \cite{cite03}\cite{cite05}. These factors combine to create an ideal state for research related to advanced machine learning techniques, namely artifical neural networks, and the implementation of tools that can rival, and even outperform, the assessment of highly trained radiologists.

\section{Machine Learning and Artificial Neural Networks}

Broadly speaking, machine learning is a way of applying artificial intelligence to a problem through the analysis of data. Machine learning techniques assess the features, or attributes, of samples in a dataset to identify patterns in the data, and the resulting algorithm can be used to render conclusions about new inputs without human intervention \cite{cite05}. Medical imaging analysis presents what is referred to as a classification problem. The typical example of a classifcation problem is handwritten numerical digit recognition. In this example, a handwritten digit between 0 and 9 is fed into the algorithm, and the algorithm decides which of the ten digits, or classes, that handwritten digit is most liekly to belong. Specific to medical image analysis, the classifier detects abnormalities in images otherwise not present in images of the same area in healthy individuals, and renders a conclusion as to what that abnormality is.

There are several different machine learning techniques that have traditionally been used in classification problems, such as support vector machines (SVM). SVMs are an example of a supervised machine learning model, in that they work with labeled data. Every sample in the dataset includes the label, or correct answer, along with a value for each of the attributes. The SVM identifies patterns in the labeled samples to create an algorithm, and new, unlabeled samples can be processed by the algorithm and given a prediction. In the task of medical image analysis, attributes have historically been identified and designed by human experts \cite{cite06}. For example, an expert would identify abnormalities by codifying shape, texure, position and orientation of the structure \cite{cite07}.  In addition to this being labor intensive, the image features are specific to the immediate problem being explored and cannot be expected to work well for other image types \cite{cite06}.

Artifical neural networks (ANN) are another class of machine learning techniques that are increasingly being leveraged to tackle problems related to image analysis. ANNs, just like SVMs, are often utilized in a supervised manner, but do not require the painstaking process of expert-defined key attributes. Instead, ANNs learn the important features from the images themselves \cite{cite07}. This is an obvious advantage when compared to traditional machine learning methods, but the complexity of these algorithms has prevented them from achieving mainstream use until recently. Even though the theory of ANNs was introduced in the 1950s, its due to the increase in computing power and availability of high quality datasets that has allowed research in this area to flourish \cite{cite05}

\section{How ANNs Work}





math used - sigmoid function - why what does this do

back propagation

black box

what is deep learning, how does it compare with human brains

difference between types on neural networks, which are best suited to the tast

how is this service being offered, which companies are selling, what are they doing

problems, controversies, how is it being accepted. differences in how images are taken, quality

applications of neural networks Applications â€“ hip ortho, diabetic retinopathy, mammogram, melanoma detection, lung nodules, myositis



\section{Neural Networks}

\section{Infrastructure}

big data computing, how long it takes to train on these problems. GPUs vs CPUs

\section{Conclusion}

 This is my conclusion.

 
\begin{acks}

 These are my acknowledgements

\end{acks}


\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 


\appendix
 

\input{issues}


\end{document}
