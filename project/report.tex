\documentclass[sigconf]{acmart}

\input{format/i523}

\begin{document}
\title{Big Data Applications in Predicting Hospital Readmissions}

\author{Tyler Peterson}
\orcid{1234-5678-9012}
\affiliation{%
  \institution{Indiana University - School of Informatics, Computing, and Engineering}
  \streetaddress{711 N. Park Avenue}
  \city{Bloomington} 
  \state{Indiana} 
  \postcode{47408}
}
\email{typeter@iu.edu}

% The default list of authors is too long for headers}
\renewcommand{\shortauthors}{G. v. Laszewski}


\begin{abstract}

  Hospital readmissions occur when a patient is discharged from a hospital and subsequently readmitted to a hospital within a short time frame. Hospitals are held accountable and penalized for readmissions that occur within 30 days of the initial inpatient stay. In 2016, nearly 2,600 hospitals were penalized $528 million collectively for readmissions. Machine learning is increasingly being used tobuild models that predict if a patient has a high probability of being readmitted. Healthcare providers possess every-growing stores of medical data that are essential for building accurate predictive models. While most of this information is private and not widely available for research, there are a few public datasets that researchers can use to build models and gain a better understand what kind of information is significant in the task of identifying high-risk patients. One such dataset includes over 100,000 patient admissions that occurred at 130 US hospitals between 1999 and 2008 and includes many features that can be used to build models. Open-source Python tools such as scikit-learn, pandas and matplotlib have tools necessary for preparing, modeling and visualizing data. These tools can be used to model the problem of hospital readmissions by creating classifiers that assign, or classify, samples based on the probability of readmission. Machine learning techniques such as logistic regression, support vector machines and decision trees are ideal for modeling data for classification problems, and these open-source tools include methods for assessing and optimizing the algorithms. The effectiveness of machine learning in classifying patients for risk of readmission is a growing topic of study and implementation of tools for assisting health care providers will likely increase rapidly in the near future.
 
\end{abstract}

\keywords{hid331, i523, Big Data, Hospital Readmissions, Machine Learning, Classification, Python}


\maketitle

\section{Introduction}

Hospital readmissions are problematic for both patients and healthcare providers. Even a single hospital admission for a patient can be an inconvenient, expensive and anxiety-inducing major life event. For a patient to be subsequently readmitted to the hospital, the patient again experiences the negative aspects of being in a hospital, along with a diminished quality of life that accompanies a recurrent disease or medical issue. Healthcare providers are increasingly being held accountable and often penalized for an inability to keep recently discharged patients from being readmitted. It has been estimated that nearly 1 in 5 Medicare patients discharged from a hospital will be readmitted within 30 days \cite{cite05}
The Hospital Readmission Reduction Program (HRRP), which originated in 2013 as a provision in the Affordable Care Act, serves as an example of an initiative that punishes hospitals for readmissions by financially penalizing hospitals with disproportionately high readmission rates among Medicare beneficiaries \cite{cite06}. The HRRP levies a reduction in Medicare reimbursement, and uses the 'all-cause' definition for readmissions, which means that a subsequent hospital stay that occurs for any reason within 30 days of the initial stay counts against the hospital \cite{cite06}. The program focuses on patients initially admitted with a heart attack, heart failure, pneumonia, chronic obstructive pulmonary disease, a coronary artery bypass graft procedure or a hip/knee replacement procedure \cite{cite06}. If a hospital's risk-adjustment readmission rate is higher than the national average, then that hospital will be penalized. Further, the excessiveness of the rate is considered as well, ensuring that providers with the worst readmission rates have proportionately higher penalties \cite{cite06}. In 2016, the US government penalized 79 percent of US hospitals, which amounts to 2,597 instituions \cite{cite00}. The penalties for those readmissions, applied to the 2017 fiscal year reimbursements, amounted to \$528 million nationally, \$108 million higher than the previous year \cite{cite00}. 
Effectively this means that the care provided to readmitted patients is uncompensated care, which stil requires valuable resources such as medical supplies, pharmaceuticals, the occupancy of hospital bed and the attention of medical staff. HRRP has had the intended effect of bringing increased focus to readmissions, and some healthcare providers are leveraging their ever-increasing medical data stores to better understand their patients. Several organization are using machine learning to identify high-risk patients. Assessing patients for the likelihood of readmission presents a binary classification problem, where a model's goal is to come to one of two conclusions on each case. The model analyzes each patient and the patient's accompanying attributes and concludes either that the patient will be readmitted or will not be readmitted.

\subsection{Applying Machine Learning to Hospital Readmissions}

There are several studies pertaining to the effectiveness of using machine learning to build predictive models that address this problem. A 2011 study conducted a systematic review of the topic and found 26 studies discussing predictive models. These models were created using administrative claims data, electronic medical record (EMR) data, or a combination of each type of dataset \cite{cite08}. Administrative claims data is primarily gathered for billing purposes and contains information about procedures, diagnoses, length of hospital stay and location of care \cite{cite10}. The advantage of this type of data is that it typically describes large populations and is inexpensive to acquire because it's already gathered for billing \cite{cite05}. EMRs contain the basic information contained in adminstrative claim data, and also include lab data, image data and the results of various diagnostic tests, as well as social and behavioral information. Of the 26 studies reviewed by this paper, only 4 reported an area under the curve (AUC) value greater than 0.70, indicating that the other 22 models performed relatively poorly at classifying high-risk patients. Interestingly, 3 of the 4 studies with a moderately high AUC built models with clinical information found in EMRs in addition to administrative claims data, which suggests that the rich information available in EMRs adds discriminative power to the predictive models \cite{cite05}.
One study that demonstrates the power of incorporating EMR data was conducted at Mount Sinai Health System in New York, NY. Mount Sinai developed a model to predict readmissions among patients with heart failure, which is the top cause of readmission among Medicare beneficiaries \cite{cite01}. To build the model, Mount Sinai leveraged their EMR system to mine 4,205 patient attributes, including 1,763 diagnosis codes, 1,028 medications, 846 laboratory measurements, 564 surgical procedures, and 4 types of vital signs. The study used a cohort of 1,068 patients, 178 of whom were readmitted within 30 days \cite{cite01}. The model achieved a prediction accuracy rate of 83.19 percent and an AUC value of 0.78. Commenting on this outcome, Mount Sinai said that the model would benefit from the inclusion of several years of data from several different hospital sites \cite{cite01}. In other words, even more data is needed to further improve the accuracy of the model.

\section{Analysis}

Though the data used by institutions to build models is not widely available, there are a few public  datasets that can be used by machine learning practitioners to better understand how predictive modeling techniques can be applied to the task of predicting readmissions. One such dataset is a subset of de-identified information from the Cerner Corporation's Health Facts database, which is comprised of comprehensive clinical records voluntarily provided by hospitals across the United States. The information contained within this dataset includes diagnoses defined by ICD-9-CM codes, in-hospital procedures, hospital characteristics, individual provider information, lab data, pharmacy data, and demographic data, such as age, gender and race. A total of 55 attributes were gathered for each encounter \cite{cite11}.
Researchers extracted a subset of 101,766 encounters from the nearly 74 million records in the Health Facts database for the purpose of studying diabetic inpatient encounters. The admissions span 10 years from 1999 to 2008, and occurred at 130 different hospitals across the United States. The researchers used the following criteria to narrow down the dataset: 1) the encounter is an inpatient encounter 2) it was a diabetic encounter, meaning at least one diabetic diagnosis code was associated with the episode of care 3) The length of stay was between 1 and 14 days 4) the patient had at least one lab test 5) the patient was administered at least one medication \cite{cite11}. This dataset is now publicly available on the UCI Machine Learning Repository

\section{Logistic Regression}

intuition
pros and cons

\subsection{Preprocessing}
get dummies, change multi level categorical variables
multicollinearity
scale 0 to 1

only include one admit per patient, samples need to be independent

\subsection{Execute Analysis}
fitting, changing parameters

\subsection{Evaluate Analysis}
specificity and sensitivity
classification reports, f score
predict method
predict proba
decision function
ROC curve, AUC

\section{Decision Trees}

\subsection{Preprocessing}

\subsection{Execute Analysis}

\subsection{Evaluate Analysis}


\section{Support Vector Machines}

\subsection{Preprocessing}

\subsection{Execute Analysis}

\subsection{Evaluate Analysis}



\section{Dimensionality Reduction}

PCA

\section{Model Optimization}

Cross validation, GridsearchCV

\section{How To Improve Analysis}

Additional features, socioeconomic status(SES)

additional studies that includes SES, do they improve?

\section{Pitfalls}

overfitting
curse of dimensionality

\section{Incorporating By The Bedside}
bedside alerts, discharge planning, case management team assignment, home care

\section{Previous Analyses}

flaws in methodology
additional data points

\section{figures}

In Figure \ref{f:fly} we show a fly. Please note that because we use
just columwidth that the size of the figure will change to the
columnwidth of the paper once we change the layout to final. CHnaging
the layout to final should not be done by you. All figures will be
listed at the end.

\begin{figure}[!ht]
  \centering\includegraphics[width=\columnwidth]{images/rossette.pdf}
  \caption{Example caption}\label{f:fly}
\end{figure}

When copying the example, please do not check in the images from the
examples into your images directory as you will not need them for your
paper. Instead use images that you like to include. If you do not have
any images, do not dreate the images folder.

\section{Conclusion}

This is my conclusion

\begin{acks}

  The authors would like to thank Dr. Gregor von Laszewski for his
  support and suggestions to write this paper.

\end{acks}

\bibliographystyle{ACM-Reference-Format}
\bibliography{report} 

\appendix

\input{issues}

\end{document}
